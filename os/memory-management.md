

> 주소 바인딩



메모리는 주소를 통해 접근하는 매체



### 논리적, 물리적 주소



+ 논리적 주소 (*Logical address* / *Virtual address*  )
  +  프로세스마다 독립적으로 가지는 주소공간
  +  각 프로세스마다 0번지부터 시작
  +  CPU가 보는 주소는 논리적 주소
     
  
+ 물리적 주소 (*Physical address*)
  + 메모리에 실제 올라가는 위치



+ 주소 바인딩: 주소를 결정하는 것

  + Symbolic Address ---> Logical Address ---(<u>이 시점이 언제인가?</u>)---> Physical address

  + 심볼릭 어드레스

    + 프로그래머는 심볼로 된 주소 사용

    + 이게 컴파일 되면 숫자로 된 로지컬 어드레스가 만들어진다. 

      

### 주소 바인딩

CPU가 바라보는 주소는 logical address다. 

주소를 바인딩하는 방식은 프로그램이 적재되는 물리적 메모리의 주소가 결정되는 시기에 따라 세 가지로 분류될 수 있다. 



+ 컴파일 타임 바인딩 (Compile time binding)
  + **프로그램을 컴파일할때** 물리적 메모리의 주소가 결정됨
  + 컴파일 이후 프로그램이 올라가 있는 물리적 메모리의 위치를 변경하고자한다면 다시 컴파일 해야한다.
  + 현대의 시분할 컴퓨팅 환경에선 잘 사용하지 않는다. 

+ 로드 타임 바인딩 (Load time binding)
  + **프로그램의 실행이 시작될때** 프로그램의 물리적 메모리 주소가 결정됨
  + 컴파일러가 relocatable code를 생성한 경우 가능하다. 

+ 실행 타임 바인딩 (Execution time binding / Run time binding)
  + 프로그램 실행 이우헤도 프로세스의 메모리상 위치를 옮길 수 있다.
  + CPU가 주소를 참조할때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지 address mapping table을 통해 binding을 점검해야한다.
  + **MMU** 라는 하드웨어적인 지원이 필요하다. 



<img width="926" alt="스크린샷 2021-04-27 오후 8 14 40" src="https://user-images.githubusercontent.com/31922389/116249190-848ad480-a7a7-11eb-9dbf-a3c70e7b8175.png">



+ ### MMU (Memory Management Unit)

  + 논리적 주소를 물리적 주소로 매핑해주는 하드웨어적 장치 (기준 레지스터와 한계 레지스터로 이루어짐)
  + MMU 기법은 CPU가 특정 프로세스의 논리적 주소를 참조하려할때 그 주소값에 *기준 레지스터*의 값을 더해 물리적 주소값을 얻어낸다. 
    + **<u>기준 레지스터(basic register)</u>**
      + 재배치 레지스터(relocation register) 라고도 한다
      + 해당 프로세스의 물리적 메모리 시작주소를 가지고 있다. 
  + MMU 기법은 프로그램의 주소공간이 물리적 메모리의 한 장소에 연속적으로 적재되는 것으로 가정한다. 
    + 그러므로 해당 프로그램이 적재되는 물리적 메모리상의 시작 주소만 알면 주소 변환을 쉽게 할 수 있다.
  + MMU 기법에서 사용자 프로그램이나 CPU는 <u>논리적 주소만 다룬다.</u> 
  + CPU가 논리적 주소 100을 참조한다고 할 때 재배치 레지스터에 저장된 프로세스의 물리적 시작주소에 100을 더해서 CPU가 요청하는 프로세스의 물리적 주소를 알아낼 수 있다.
    + Context Switching마다 재배치 레지스터에 저장된 프로세스의 물리적 시작주소가 Update된다. 
  + 다중 프로그래밍 환경에서 물리적 메모리 안에 여러개의 프로세스가 동시에 올라와 있는 경우가 대부분이다. 
    + 위 방식을 선택했을 경우 [CPU가 요청한 논리적 주소 + 재배치 레지스터 안의 물리적 시작주소] 의 결과가 실제 메모리에서 벗어나는 문제가 발생할 수 있다.
      + 이런 상황을 방지하기 위해 **한계 레지스터**를 사용한다. 
    + **<u>한계 레지스터(limit resigster)</u>**
      + 프로세스가 자신의 주소 공간을 넘어서는 메로리 참조를 하려하는지 체크
      + 현재 CPU에서 수행중인 프로세스의 크기를 담고 있다. 
      + 만약 실제 프로그램 크기보다 논리적 주소 크기가 크다면 trap 걸어서 addressing error






<img width="921" alt="스크린샷 2021-04-27 오후 8 27 23" src="https://user-images.githubusercontent.com/31922389/116403454-89fc2380-a868-11eb-80df-5138ed60a13b.png"  >





---



> 메모리와 관련된 용어



+ 동적 로딩
+ 동적 연결
+ 중첩 (overlays)
+ 스와핑 (swapping)

---



### Dynamic Loading



+ 프로세스 전체를 메모리에 다 올리는 방식이 아닌 해당 루틴이 불려질때 메모리에 load하는 방식

+ 프로그램의 대부분을 차지하는 코드들은 오류처리 루틴이다. 이 루틴들은 늘 사용되진 않는다. 

  + 처음에 올려놓지 않고 필요한 상황이 생기면 그때 load한다. 

+ 운영체제의 특별한 지원 없이 프로그램 자체에서 구현 가능

+ 운영체제가 라이브러리를 통해 지원할 수 있다. 

+ 지금 OS의 페이징 기법은 운영체제가 직접 관리

  + 하지만 개념적인건 프로그래머가 결정

  + 프로그래머가 직접하는건 아니고 라이브러리의 힘을 빌려 구현

  

### Overlays

+ 프로세스의 주소공간을 분할해 실제 필요한 부분만을 메모리에 적재하는 기법
+ 동적 로딩과 개념적으로 유사하지만 사용하는 이유는 다르다.
  + 동적 로딩
    + 다중 프로그래밍 환경에서 메모리의 이용률을 향상시키기 위해
    + 메모리에 더 많은 프로세스를 동시에 올려놓고 실행하기 위한 <u>전략</u>
  + 오버레이
    + 단일 프로세스만을 메모리에 올려놓는 환경에서 메모리 용량보다 큰 프로세스를 실행하기 위한 <u>어쩔수없는 선택</u>
+ 프로그래머가 프로그램을 실행시킬때 <u>수작업으로 쪼개서 메모리에 올리도록 함</u>
+ 운영체제의 지원이 없음





### Swapping

스와핑: 메모리에 올라온 프로세스의 주소공간 전체를 디스크의 스왑영역에 일시적으로 내려 놓는 것



+ Backing Store (= swap area)
  + 디스크 내 파일 시스템과는 별도로 존재하는 일정 영역
    + 파일 시스템:  비휘발성 저장공간
    + 스왑 영역: 프로세스가 수행중일 경우에만 디스크에 일시적으로 저장 (휘발성)
  + 다수의 사용자 프로세스를 담을 수 있을만큼 용량이 크고 접근 속도가 빨라야한다.



+ Swap in / Swap out

  + Swap in : 디스크에서 메모리로 올리는 작업

  + Swap out: 메모리에서 디스크로 내리는 작업
  + 스와핑: 중기 스케쥴러에 의해 스왑 아웃시킬 프로세스를 선택한다. 

+ 컴파일 타임 바인딩 or 로드 타임 바인딩에선 원래 메모리 위치로 swap in

+ 실행 타임 바인딩에선 빈 위치에 아무데나 swap in 가능

+ 역할: 메모리에 있는 프로세스의 수 조절

+ 소요 시간: 탐색 시간 (seek time)  or 회전지연시간(rotational latenct) <<<<< 전송시간(transfer time)





### Dynamic Linking

+ linking: 목적파일과 라이브러리 파일들을 묶어 하나의 실행파일을 생성하는 과정
  + objet file: 프로그래머가 작성한 소스코드를 컴파일해서 생성된 파일
  + library file: 이미 컴파일된 파일
+ Static linking
  + 라이브러리가 프로그램의 실행파일 코드에 포함됨
  + 실행파일의 크키가 커짐
  + 동일한 라이브러리를 각가의 프로세스가 메모리에 올리므로 메모리 낭비
    + eg. printf 함수의 라이브러리 코드

+ Dynamic linking
  + <u>Linking을 execution time 까지 미루는 기법</u>
  + 라이브러리가 실행시 link됨
  + 라이브러리 호출 부분에 라이브러리 루틴의 위치를 찾기 위한 stub(작은 코드)을 둠
  + 라이브러리가 이미 메모리에 있으면 그 루틴의 주소로 가고 없다면 디스크에서 읽어옴
  + 운영체제의 도움 필요
  + 다이나믹 링킹을 하는 shared library 파일
    + 윈도우에서는 DLL , 리눅스에선 shared object





> 물리적 메모리의 할당 방식

+ 연속 할당 방식
  + 고정 분할 방식
  + 가변 분할 방식
+ 불연속 할당 방식
  + 페이징 기법
  + 세그멘테이션 기법
  + 페이지드 세그멘테이션 기법



### Allocation of Physical Memory

+ 메모리는 두 영역으로 나눠서 사용
  + OS 상주 영역
    + 낮은 주소
  + 사용자 프로세스 영역
    + 높은 주소
+ 사용자 프로세스 영역의 할당 방법
  + Contiguous Allocation (연속적 할당)
    + 물리적 메모리를 다수의 분할로 나누어 <u>하나의 분할에 하나의  프로세스가 적재되도록 함</u>	
      + Fixed Partition Allocation (고정분할)
      + Variable Paritition Allocation (가변분할)
    
  + Noncontiguous Allocation (불연속적 할당)
    + <u>하나의 프로세스를 물리적 메모리의 여러 영역에 분산하여 적재되도록 함</u>
    + *현대 시스템에선 불연속적 할당 사용*
      + Paging
      + Segmentation
      + Paged Segmentation





### 연속할당

<img width="944" alt="스크린샷 2021-04-27 오후 8 57 12" src="https://user-images.githubusercontent.com/31922389/116403688-d8a9bd80-a868-11eb-9d5c-07a397d964ca.png"> 

#### 고정분할

+ 물리적 메모리를 주어진 개수만큼의 영구적인 분할로 미리 나눠두고 각 분할에 하나의 프로세스를 적재해서 실행되도록 한다. 

+ 단점: 낭비되는 조각들이 생김
  + 외부 조각
    + 프로세스를 할당하기에 메모리 조각의 크기가 작아서 놀고있는 메모리 조각
  + 내부 조각
    + 프로세스의 크기보다 더 큰 메모리 조각이 할당돼서 남아서 놀고있는 메모리 조각

#### 가변분할

+ 메모리에 적재되는 프로그램의 크기에 따라 분할의 크기 및 개수가 동적으로 변하는 방식
+ 내부조각은 발생하지 않음
+ 외부조각 발생 가능성
  + 프로그램이 종료하고 나서 빈 메모리 공간에 들어갈 프로세스가 없을 경우 (프로세스가 들어가기에 공간이 적음)



### Hole

+ 가용 메모리 공간
+ 다양한 크기의 hole들이 메모리 여러곳에 흩어져있음
+ 프로세스가 도착하면 수용가능한 hole을 할당
+ 운영체제는 Hole과 사용되고 있는 메모리 공간을 각각 관리하고 있어야한다. 



### 동적 메모리 할당 문제

주소공간의 크기가 n인 프로세스를 메모리에 올릴때 물리적 메모리 내 가용 공간중 어떤 위치에 올릴것인지 결정



<img width="908" alt="스크린샷 2021-04-27 오후 9 07 27" src="https://user-images.githubusercontent.com/31922389/116403788-f6772280-a868-11eb-83e5-db70f4a91887.png">





### Compaction

+ 외부조각 문제를 해결하는 한가지 방법
+ 여러가지에 모여있는 hole을 한곳으로 미는 작업

+ 매우 비용 많이 듦

+ 런타임 바인딩이 지원되는 상황에서 가능



------> <u>컴팩션보다 최소한의 이동으로 큰 hole을 만드는게 좋다.</u> 











